{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Exploring Bivariate Relationships and Working with Weights\n",
    "\n",
    "In Notebook 3, we learned how to explore our variables, recode categorical variables into dummies, and clean and/or classify our numeric variables.\n",
    "\n",
    "In today's lab, we're going to focus on\n",
    "\n",
    "> Exploring relationships between two variables\n",
    "\n",
    "We will also be introducing the concept of weights.  **USING WEIGHTS THIS SEMESTER IS OPTIONAL.**  But it is helpful to know what they are and how they work if you ever encounter them in a professional setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Reading in our libraries, our dataset, and renaming our variables\n",
    "\n",
    "Just the intro material!  Remember, you need to run all the cells in order - libraries, read data, and rename data, otherwise Python will give you an error message!  Note that there is a new datafile that includes the RAKEDW0 variable - this is our weight variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, We're going to call in our libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "from datascience import *\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show our plots in the Jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we start working with nan (missing) values, we can get warnings - we're going to ignore them here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we're going to read in our data\n",
    "\n",
    "# Here is my code for reading in the complete CHIS data 2\n",
    "\n",
    "# col_list = ['AC47', 'AC42', 'SRSEX', 'AC46', 'POVLL', 'AE_VEGI', 'OMBSRR_P1','POVGWD_P1','RAKEDW0']\n",
    "#chis_df=pd.read_csv(\"CHIS_2018_Adult_All.csv\", usecols=col_list)\n",
    "#chis_df\n",
    "\n",
    "#today we're going to work with the extract as we did last week\n",
    "\n",
    "chis_df = pd.read_csv('chis_extract_2018_weights.csv')\n",
    "chis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df.rename(columns={'AC47':'drank_water', \n",
    "                        'AC42':'nhood_fv', \n",
    "                        'AE_VEGI':'ate_fv',\n",
    "                        'SRSEX': 'sex',\n",
    "                        'AC46': 'drank_sweet',\n",
    "                        'OMBSRR_P1': 'race_ethnicity',\n",
    "                        'POVGWD_P1' : 'pov_ratio',\n",
    "                       'POVLL' : 'pov_cat',\n",
    "                       'RAKEDW0': 'weight'}, inplace=True)\n",
    "chis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codebook\n",
    "\n",
    "> AC46: Number of times respondent drank sweet fruit drinks in past month\n",
    "\n",
    "> AC47: Number of times respondent drank water yesterday\n",
    "\n",
    "> AE_VEGI: Number of times respondent eats vegetables per week\n",
    "\n",
    "> AC42: Number of times respondent was able to find fresh fruits/vegetables in neighborhood\n",
    "(1=Never, 2=Sometimes, 3 = Usually, 4 = Always, 5=Doesn't eat f/v, 6: Doesn't shop for f/v, 7 Doesn't shop in neighborhood)\n",
    "\n",
    "> SRSEX: Self-reported Sex (1= Male, 2=Female)\n",
    "\n",
    "> OMBSRR_P1: Race/ethnicity\n",
    "(1=Hispanic, 2= White NH, 3=Black NH, 4=AmIndian/Alaska Native NH, 5=Asian NH, 6=Other or two or more)\n",
    "\n",
    "> POVLL: poverty level\n",
    "(1 = 0-99% FPL, 2=100-199% FPL, 3=200-299% FPL, 4=300% FPL and above)\n",
    "\n",
    "> POVGWD_P1: Family Poverty Threshold Level\n",
    "\n",
    "> RAKEDW0: Individual weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.0  Exploring Bivariate Relationships\n",
    "\n",
    "### 2.1 Hypothesis\n",
    "\n",
    "Let's start by reminding ourselves why we're doing all this data cleaning!  I am a city planner interested in the issue of soda taxes.   I am concerned that people in poverty will disporportionately bear the burden of a soda tax.  \n",
    "\n",
    "**My hypothesis is that people who are poor are more likely to drink sweet fruit drinks/sodas, so this is a regressive tax.**\n",
    "\n",
    ">  Y Variable: Number of Sodas/Sweet Drinks (AC46 - renamed drank_sweet)\n",
    "\n",
    ">  X Variable: Ratio of income to poverty line  (POVGWD_P1  - renamed pov_ratio)\n",
    "\n",
    ">  Alternate X Variable: Categorical poverty level (POVLL - renamed pov_cat)\n",
    "\n",
    "Below, I've included the code I used to clean each of the variables, including notes about what I did and why!\n",
    "\n",
    "**I'm also going to create a \"text\" race/ethnicity variable to explore if there might be differences by race/ethnicity.  This is mostly to show you another option for working with your data in Python!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Cleaning my variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2a Clean my Y variable (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe the distribution of my data\n",
    "chis_df['drank_sweet'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at it visually with a histogram - clear there's lots of 0's, and 300 is a clear outlier\n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
    "sns.distplot(\n",
    "    chis_df['drank_sweet'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
    ").set(xlabel='drank_sweet', ylabel='Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop observations 3 StDev from the mean for the \"drank_sweet\" variable\n",
    "chis_df=chis_df[(np.abs(stats.zscore(chis_df['drank_sweet'], nan_policy='omit'))<3)]\n",
    "chis_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check distribution again - looks better! \n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
    "sns.distplot(\n",
    "    chis_df['drank_sweet'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
    ").set(xlabel='drank_sweet', ylabel='Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2b  Clean my X variable (poverty as a ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df['pov_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at it visually with a histogram - this looks pretty good so I'm going to leave it as is\n",
    "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
    "sns.distplot(\n",
    "    chis_df['pov_ratio'], norm_hist=False, kde=False, bins=20, hist_kws={\"alpha\": 1}\n",
    ").set(xlabel='pov_ratio', ylabel='Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2c Clean my X variable (poverty as category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of values\n",
    "pd.crosstab(chis_df['pov_cat'], columns='Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because I am most concerned about households living under the poverty line, \n",
    "#I'm going to create a dummy where 1 = under the poverty line, and 0 is above\n",
    "\n",
    "chis_df['inpoverty_dv']=chis_df['pov_cat'].map({1:1, 2:0, 3:0, 4:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that it's good to double check when creating new variables\n",
    "pd.crosstab(chis_df['inpoverty_dv'], columns='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sometimes, I want a categorical variable with text so I can quickly look at my data - here's one way to create a new categorical variable with the values replaced by text strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code creates a new column with a categorical race variable based on the dummies\n",
    "#OMBSRR_P1: Race/ethnicity (1=Hispanic, 2= White NH, 3=Black NH, 4=AmIndian/Alaska Native NH, 5=Asian NH, 6=Other or two or more)\n",
    "chis_df.loc[(chis_df['race_ethnicity'] == 2), 'race_eth_text'] = 'NHWhite'  \n",
    "chis_df.loc[(chis_df['race_ethnicity']==5), 'race_eth_text'] = \"Asian\"\n",
    "chis_df.loc[(chis_df['race_ethnicity']==3), 'race_eth_text'] = \"Black\"\n",
    "chis_df.loc[(chis_df['race_ethnicity']==1), 'race_eth_text'] = \"Hispanic\"\n",
    "chis_df.loc[(chis_df['race_ethnicity']==4), 'race_eth_text'] = \"Other/Two Races\"\n",
    "chis_df.loc[(chis_df['race_ethnicity']==6), 'race_eth_text'] = \"Other/Two Races\"\n",
    "chis_df['race_eth_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Exploring relationships\n",
    "\n",
    "Now that I've cleaned my data, I can start to explore whether or not there are relationships between my Y and X variables.  I'm going to explore whether there are any observable differences in the average number of sweet drinks a person consumes by my poverty variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1  Exploring a numeric variable grouped by a dummy or categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see if the average number of sweet drinks varies by poverty category\n",
    "chis_df[\"drank_sweet\"].groupby(chis_df[\"pov_cat\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I want to look at different metrics, like median, min or max, I can do that too\n",
    "#What do each of these columns mean?\n",
    "chis_df[\"drank_sweet\"].groupby(chis_df[\"pov_cat\"]).agg(['count', 'sum','mean', 'median', 'min', 'max', 'std', 'sem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try it yourself - calculate mean scores for a numeric variable, grouping by a dummy in your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can also explore by race/ethnicity - here's where the \"text\" version benefits me - \n",
    "#I don't have to remember what the number values stand for\n",
    "chis_df[\"drank_sweet\"].groupby(chis_df[\"race_eth_text\"]).agg(['count', 'sum','mean', 'median', 'min', 'max', 'std', 'sem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A useful tip for Assignment 4 - you can assign the analysis above to an object, and then export it as a .csv\n",
    "results_race_eth=chis_df[\"drank_sweet\"].groupby(chis_df[\"race_eth_text\"]).agg(['count', 'sum','mean', 'median', 'min', 'max', 'std', 'sem'])\n",
    "results_race_eth.to_csv(\"results_race_eth.csv\", index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2  Exploring the relationship between two dummy or categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=chis_df[\"race_eth_text\"], columns=chis_df[\"inpoverty_dv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If I want to explore the relationship between two dummy or categorical variables, I'm going to use the pandas crosstab function.  \n",
    "#Take a minute to explore what the margins and normalize code did.  \n",
    "pd.crosstab(index=chis_df[\"race_eth_text\"], columns=chis_df[\"inpoverty_dv\"], margins=True, normalize='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's write out two sentences that describe these data that we can refer back to.\n",
    "\n",
    "Replace this with a sentence describing the data normalized by columns.\n",
    "\n",
    "Replace this with a sentence describing the data normalized by rows (index)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2  Exploring the relationship between two numeric variables variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the relationship between two numeric variables is generally done with a scatterplot\n",
    "# Because both are numeric, there are too many values to use \"groupby\"\n",
    "plt.scatter(chis_df[\"pov_ratio\"], chis_df[\"drank_sweet\"], s=5)\n",
    "plt.xlabel(\"Poverty Ratio\")\n",
    "plt.ylabel(\"Drank Sweet/Soda Drinks\")\n",
    "\n",
    "#it's still pretty hard to assess, right? It's because we have so many observations\n",
    "#and because there are a lot of people who drink soda!\n",
    "#That's why we'll calculate correlations later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another fun way to visualize!!\n",
    "sns.relplot(x=\"pov_ratio\", y=\"drank_sweet\", hue=\"race_eth_text\", data=chis_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Survey Weights \n",
    "\n",
    "When official agencies run a survey (like CHIS, PUMS, AHS, and NHTS), they often include weights that allow the user to calculate total population estimates from survey responses to reduce survey bias. Simply, weighting assists in making our sample of survey respondents (more) representative of the population.  The weighting process usually involves three steps: (i) obtain the design weights, which account for sample selection; (ii) adjust these weights to compensate for nonresponse; (iii) adjust the weights so that the estimates coincide to some known totals of the population, which is called calibration.\n",
    "\n",
    "The literature on weighting is vast, and for those of you who are going to move on to more advanced statistical techniques, you will learn a lot more about weighting than I can do justice here.  But, it is useful to explore how using weights in descriptive statistics can change your results.\n",
    "\n",
    "Statistical packages tend to have sophisticated functions to apply weights - I wasn't able to find similarly elegant solutions for Python.  But below are two approaches if you'd like to try using weights in your descriptive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1. Weighting: First Approach for Means and Total Counts**\n",
    "\n",
    "The cell below is a set of code where I define two separate \"helper\" functions.  The first is to calculate a weighted mean, the second is to create a weighted sum.  You run this cell, and then you use the **w_mean** and **w_sum** functions in subsequent cells to specify the output you want.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample weights helper function for weighted mean.\n",
    "def w_mean(frame, mean_var, weight):  #this line of code defines the function w_mean, as having to specify a data frame, a variable, and a weight\n",
    "    d = frame[mean_var]\n",
    "    w = frame[weight]\n",
    "    try: \n",
    "        return (d * w).sum() / w.sum() #this calculates the weighted mean\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "# Sample weights helper function for weighted sum.\n",
    "def w_sum(frame, sum_var, weight):\n",
    "    d = frame[sum_var]\n",
    "    w = frame[weight]\n",
    "    try: \n",
    "        return (d * w).sum()\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first take a look at the distribution of sweet drinks by race/ethnicity without weights\n",
    "chis_df[\"drank_sweet\"].groupby(chis_df[\"race_eth_text\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, with weights - what happens to the mean number of sweet drinks by race/ethnicity?\n",
    "chis_df.groupby('race_eth_text').apply(w_mean, 'drank_sweet', 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, let's first look at the number of respondents who are under the poverty line\n",
    "chis_df['inpoverty_dv'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, with weights\n",
    "w_sum(chis_df, 'inpoverty_dv', 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of respondents by race/ethnicity who are under the poverty line without weights\n",
    "chis_df[\"inpoverty_dv\"].groupby(chis_df[\"race_eth_text\"]).agg(['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted counts of the number of people under the poverty line by race/ethnicity\n",
    "chis_df.groupby('race_eth_text').apply(w_sum, 'inpoverty_dv', 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2. Weighting: Approach 2 - use weightedcalcs library**\n",
    "\n",
    "I found this cool library that does weighted calculations for you on github.  The example python notebook can be found here:\n",
    "https://github.com/jsvine/weightedcalcs/tree/master/examples/notebooks .  This also provides an example of how you have to sometimes install a new library, even in datahub.  The command is pip install --user and then the name of the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user weightedcalcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weightedcalcs as wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line of code assigns which variable will be the \"weight\" variable in the calculator\n",
    "calc = wc.Calculator(\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chis_df['drank_sweet'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I caclulate the weighted mean number of drinks\n",
    "calc.mean(chis_df, \"drank_sweet\").round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without weights\n",
    "pd.crosstab(chis_df['inpoverty_dv'], columns='Total', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with weights\n",
    "calc.distribution(chis_df, \"inpoverty_dv\").round(3).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to calculate statistics across a groupby variable, you need to create a new object\n",
    "grp_race_eth= chis_df.groupby([\"race_eth_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc.mean(grp_race_eth, \"drank_sweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Conclusion\n",
    "\n",
    "If you don't feel like you want to apply weights, just be clear that the N in your table and any descriptive statistics are based on the sample data, and not the population.  As with everything, as long as you document your choices, you'll be using data ethically!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
